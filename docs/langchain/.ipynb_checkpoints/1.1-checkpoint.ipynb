{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0641ed5-bb30-40de-9696-35f2c83d8634",
   "metadata": {},
   "source": [
    "## 前置\n",
    "- huggingface https://huggingface.co/\n",
    "- 魔搭 https://www.modelscope.cn/docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c4b00-b969-463e-b45e-bbc442ce081f",
   "metadata": {},
   "source": [
    "## 情人节玫瑰宣传语"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ae318-1aae-4576-8d83-473168b9693c",
   "metadata": {},
   "source": [
    "### 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65e85d-a7d5-48a2-8eaf-97ad46fad130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c43e3-a2e5-4fb3-bad1-2e3d068d3351",
   "metadata": {},
   "source": [
    "### 执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec6495b7-a8d0-452c-a23d-e992babbd9e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Incorrect API key provided: sk-vMKA4***************************************Cd4t. You can find your API key at https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m请给我写一句情人节红玫瑰的中文宣传语\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/langchain/llms/base.py:825\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    823\u001b[0m     )\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    835\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/langchain/llms/base.py:621\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    616\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    617\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m), [prompt], invocation_params\u001b[38;5;241m=\u001b[39mparams, options\u001b[38;5;241m=\u001b[39moptions\n\u001b[1;32m    618\u001b[0m         )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    619\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m callback_manager, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(callback_managers, prompts)\n\u001b[1;32m    620\u001b[0m     ]\n\u001b[0;32m--> 621\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/langchain/llms/base.py:523\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    522\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    524\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/langchain/llms/base.py:510\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    502\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    507\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 510\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    514\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    518\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    519\u001b[0m         )\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/langchain/llms/openai.py:385\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     choices\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    374\u001b[0m         {\n\u001b[1;32m    375\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: generation\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m         }\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     choices\u001b[38;5;241m.\u001b[39mextend(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    389\u001b[0m     update_token_usage(_keys, response, token_usage)\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/langchain/llms/openai.py:115\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/langchain/llms/openai.py:113\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Incorrect API key provided: sk-vMKA4***************************************Cd4t. You can find your API key at https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-davinci-003\",max_tokens=200)\n",
    "text = llm(\"请给我写一句情人节红玫瑰的中文宣传语\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f55bb-9022-4123-a634-0b481061a6eb",
   "metadata": {},
   "source": [
    "## 海报文案生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401d324-fd59-48cc-b8ad-20bf6bc4a148",
   "metadata": {},
   "source": [
    "### 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c63ae51-a802-4263-914c-65549195e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade langchain\n",
    "!pip install transformers\n",
    "!pip install pillow\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca77d2-f2f4-4ac9-a687-a91d776cfe9e",
   "metadata": {},
   "source": [
    "### 执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eb477b7-7446-407e-a4f9-36ac7d470da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m 应该思考如何给图片创作合适的文案\n",
      "Action: Image captioner\n",
      "Action Input: https://static001.geekbang.org/resource/image/15/6e/150884666d8ea7e21b12c8e3ccd3b26e.jpg\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mthere is a large jetliner flying over a small town\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 根据观察结果，可以推断出图片的内容\n",
      "Final Answer: 一架大型客机正在小镇上空飞行\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'一架大型客机正在小镇上空飞行'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---- Part 0 导入所需要的类\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from langchain.tools import BaseTool\n",
    "from langchain import OpenAI\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "#---- Part I 初始化图像字幕生成模型\n",
    "# 指定要使用的工具模型（HuggingFace中的image-caption模型）\n",
    "hf_model = \"Salesforce/blip-image-captioning-large\"\n",
    "\n",
    "# 初始化处理器和工具模型\n",
    "# 预处理器将准备图像供模型使用\n",
    "processor = BlipProcessor.from_pretrained(hf_model)\n",
    "# 然后我们初始化工具模型本身\n",
    "model = BlipForConditionalGeneration.from_pretrained(hf_model)\n",
    "\n",
    "#---- Part II 定义图像字幕生成工具类\n",
    "class ImageCapTool(BaseTool):\n",
    "   \n",
    "    name = \"Image captioner\"\n",
    "    description = \"为图片创作说明文案.\"\n",
    "\n",
    "    def _run(self, url: str):\n",
    "        # 下载图像并将其转换为PIL对象\n",
    "        image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
    "        # 预处理图像\n",
    "        inputs = processor(image, return_tensors=\"pt\")\n",
    "        # 生成字幕\n",
    "        out = model.generate(**inputs, max_new_tokens=20)\n",
    "        # 获取字幕\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    \n",
    "    def _arun(self, query: str):\n",
    "        raise NotImplementedError(\"This tool does not support async\")\n",
    "\n",
    "#---- PartIII 初始化并运行LangChain智能代理\n",
    "# 设置OpenAI的API密钥并初始化大语言模型（OpenAI的Text模型）\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "llm = OpenAI(temperature=0.2)\n",
    "\n",
    "# 使用工具初始化智能代理并运行它\n",
    "tools = [ImageCapTool()]\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "# img_url = 'https://static001.geekbang.org/resource/image/15/6e/150884666d8ea7e21b12c8e3ccd3b26e.jpg'\n",
    "img_url = 'https://mir-s3-cdn-cf.behance.net/project_modules/hd/eec79e20058499.563190744f903.jpg'\n",
    "\n",
    "agent.run(input=f\"{img_url}\\n请给出合适的中文文案\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a8fcd2-9822-4a4f-b67d-a66e68fb5863",
   "metadata": {},
   "source": [
    "## 魔搭达模型\n",
    "教程：https://www.modelscope.cn/docs/%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4b093-6289-4466-b41e-c342f45ce80b",
   "metadata": {},
   "source": [
    "### 安装依赖\n",
    "参考模型 https://modelscope.cn/models/baichuan-inc/Baichuan2-13B-Chat/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a476b614-085f-45e0-b52b-3c35bf0160f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Looking in links: https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html\n",
      "Requirement already satisfied: modelscope[audio,cv,multi-modal,nlp,science] in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (1.9.0)\n",
      "Requirement already satisfied: addict in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.4.0)\n",
      "Requirement already satisfied: attrs in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (22.1.0)\n",
      "Requirement already satisfied: datasets<=2.13.0,>=2.8.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.12.0)\n",
      "Requirement already satisfied: einops in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.6.1)\n",
      "Requirement already satisfied: filelock>=3.3.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (3.9.0)\n",
      "Requirement already satisfied: gast>=0.2.2 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.5.4)\n",
      "Requirement already satisfied: ms-swift in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (1.0.0)\n",
      "Requirement already satisfied: numpy in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (1.24.3)\n",
      "Requirement already satisfied: oss2 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.18.1)\n",
      "Requirement already satisfied: pandas in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (1.5.3)\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (9.4.0)\n",
      "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (6.0)\n",
      "Requirement already satisfied: requests>=2.25 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.29.0)\n",
      "Requirement already satisfied: scipy in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (1.10.1)\n",
      "Requirement already satisfied: setuptools in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (67.8.0)\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (3.19.1)\n",
      "Requirement already satisfied: sortedcontainers>=1.5.9 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (4.65.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (1.26.16)\n",
      "Requirement already satisfied: yapf in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.31.0)\n",
      "Requirement already satisfied: accelerate in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.22.0)\n",
      "Collecting albumentations>=1.0.3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9b/f6/c486cedb4f75147232f32ec4c97026714cfef7c7e247a1f0427bc5489f66/albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "Collecting av>=9.2.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/31/f2/476757c405e3e0dc4fc4a74cb6b9a68ac088672d3598864b20ce7607d03e/av-10.0.0-cp39-cp39-macosx_11_0_arm64.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting bmt-clipit>=1.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/bmt_clipit-1.0-py3-none-any.whl (42 kB)\n",
      "Collecting chumpy (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/01/f7/865755c8bdb837841938de622e6c8b5cb6b1c933bde3bd3332f0cd4574f1/chumpy-0.70.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting clip>=1.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/clip-1.0-py3-none-any.whl (1.4 MB)\n",
      "Collecting control-ldm (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/diffusion/control_ldm-0.0.1-py3-none-any.whl (113 kB)\n",
      "Collecting ddpm-guided-diffusion (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/ddpm_guided_diffusion-0.0.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: diffusers in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.20.2)\n",
      "Collecting easydict (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/55/83/0d1ee7962f3ba3fbe9eebe67eb484f6745995c9af045c0ebe5f33564cba0/easydict-1.10.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting easyrobust (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/44/60/66a8ace4ff949f6f9fdb310b66d8dbd6c50341fe6df96dd870302c4f50ee/easyrobust-0.2.4.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting edit-distance (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/21/1d/559e453bc451ab12c7cb79b953f108ed92b378fb8ea4296db1d7c62bbb5e/edit_distance-1.0.6-py3-none-any.whl (11 kB)\n",
      "Collecting face-alignment>=1.3.5 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a1/7e/36e212aa11d227a6d9afae540e91f161a7db3ad28177804403fe45fda5e2/face_alignment-1.4.1-py2.py3-none-any.whl (30 kB)\n",
      "Collecting fairscale>=0.4.1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c1/08/b3334d7b543ac10dcb129cef4f84723ab696725512f18d69ab3a784b0bf5/fairscale-0.4.13.tar.gz (266 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastai>=1.0.51 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ad/dc/3de82e8f941a09d52a2b5c787a9f67a2e38c5e087336ad4dcfa7bb6e34d8/fastai-2.7.12-py3-none-any.whl (233 kB)\n",
      "Collecting ffmpeg>=1.4 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ffmpeg-python>=0.2.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting ftfy (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e1/1e/bf736f9576a8979752b826b75cbd83663ff86634ea3055a766e2d8ad3ee5/ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting fvcore (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a5/93/d056a9c4efc6c79ba7b5159cc66bb436db93d2cc46dca18ed65c59cc8e4e/fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting healpy (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/76/f7/9442e25555c4952584a0c6d9d350964955b73101a6a5fca98e74344bf9e7/healpy-1.16.5.tar.gz (4.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: imageio>=2.9.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.26.0)\n",
      "Collecting imageio-ffmpeg>=0.4.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/28/c6/7f9990d8f9378bb4b8c60c08c2a1f565c44d9445c1f01fbbd5bed21379d9/imageio-ffmpeg-0.4.9.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting imgaug>=0.4.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "Collecting kornia>=0.5.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/55/da/72cb83aa364ebb4d0109965e20c5d33d7063ccab15332c3fd0acfd5609c9/kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n",
      "Collecting lap (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lmdb (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/de/13/dd9b0c1924f0becc93e0bacd123a4e7a347966e3e74753ace3b1e85acc39/lmdb-1.4.1.tar.gz (881 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lpips (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9b/13/1df50c7925d9d2746702719f40e864f51ed66f307b20ad32392f1ad2bb87/lpips-0.1.4-py3-none-any.whl (53 kB)\n",
      "Collecting ml-collections (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/aa/ea/853aa32dfa1006d3eb43384712f35b8f2d6f0a757b8c779d40c29e3e8515/ml_collections-0.1.1.tar.gz (77 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mmcls>=0.21.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1f/7d/19588f57c22f4053ca2db92c691fbea556899f407fe7bb03ed42b37f07ef/mmcls-0.25.0-py2.py3-none-any.whl (648 kB)\n",
      "Collecting mmdet<=2.28.2,>=2.25.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/03/ed/4ebb8197d87930b25d89ad4a72b3f36bb5f1ceea6d8bec89b22640f1a9fc/mmdet-2.28.2-py3-none-any.whl (1.5 MB)\n",
      "Collecting mmdet3d==1.0.0a1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/cv/mmdet3d-1.0.0a1-py3-none-any.whl (837 kB)\n",
      "Collecting mmsegmentation<=0.30.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f1/88/48e7c2276272123480c04952f9a9a9b928c2c8f1df9c29ab7ff705005bb2/mmsegmentation-0.30.0-py3-none-any.whl (831 kB)\n",
      "Collecting moviepy>=1.0.3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/18/54/01a8c4e35c75ca9724d19a7e4de9dc23f0ceb8769102c7de056113af61c3/moviepy-1.0.3.tar.gz (388 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nerfacc==0.2.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f6/a5/dfce98276ec453f3daaf3e30419db45bd52585899a5eca2386800d3b3c30/nerfacc-0.2.2-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: networkx in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (3.1)\n",
      "Collecting numba (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/23/21/644a5fb3f74ee8e63e59a8acc78f08ec281f5e11d07551209b02614aa6a2/numba-0.57.1-cp39-cp39-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e3/94/1843518e420fa3ed6919835845df698c7e27e183cb997394e4a670973a65/omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting onnx (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f0/39/c2c1d156b284e2c4c4731c37e52e4e2d4a6cefa65fa84dca61ff83008252/onnx-1.14.1-cp39-cp39-macosx_10_12_universal2.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime>=1.10 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/41/fe/081d49d7f1de55adf8da8f4aa1fb08416906a953c5ef08fcf7bdafd4cc02/onnxruntime-1.15.1-cp39-cp39-macosx_11_0_arm64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxsim (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/98/34/03bd30dda649ef661ca45906baaecfae2dce3f331d4b37e60f00199ff0c0/onnxsim-0.4.33-cp39-cp39-macosx_10_15_universal2.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting open-clip-torch>=2.7.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/70/b9/a9f2c37f998c20be57fed0128934f4a311c6596c1f6b9c2fe358b26125bc/open_clip_torch-2.20.0-py3-none-any.whl (1.5 MB)\n",
      "Collecting opencv-python (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/32/a6/4321f0f30ee11d6d85f49251d417f4e885fe7638b5ac50b7e3c80cccf141/opencv_python-4.8.0.76-cp37-abi3-macosx_11_0_arm64.whl (33.1 MB)\n",
      "Collecting paint-ldm (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/paint_ldm-0.0.0-py3-none-any.whl (75 kB)\n",
      "Collecting panopticapi (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/panopticapi-0.1-py3-none-any.whl (23 kB)\n",
      "Collecting plyfile>=0.7.4 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a9/3d/f5e9a58300674a638a5107980b09858bb853c527764c2220d7c840fe19d3/plyfile-1.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: psutil in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (5.9.0)\n",
      "Collecting pyclipper (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/37/bb/9e3c9f4255de75618e37ab045314b3e4283d6255aaeab5e155599979bc08/pyclipper-1.3.0.post5-cp39-cp39-macosx_10_9_universal2.whl (278 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyMCubes (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/22/4a/fd2e95b1a2010d2a21c071313472f8d7e66cb8cb3351cef1b83c5ebb7cbe/PyMCubes-0.1.4.tar.gz (109 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-lightning (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/57/8c/97edac337566f66b1aa5a08457ace7f27d0697a03626ac41713ff1ed3d5e/pytorch_lightning-2.0.8-py3-none-any.whl (727 kB)\n",
      "Requirement already satisfied: regex in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2022.7.9)\n",
      "Collecting scikit-image<0.20.0,>=0.19.3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6a/2e/98c92fa887de773360631dc54add5679d269730537be46498c1392e76215/scikit_image-0.19.3-cp39-cp39-macosx_12_0_arm64.whl (12.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.1 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (1.2.2)\n",
      "Collecting shapely (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ea/aa/45fbd031edf3149cb767d8b9f9db45d5faf0324d743c6b8fb0298cc022d0/shapely-2.0.1-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting shotdetect-scenedetect-lgss>=0.0.4 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/shotdetect_scenedetect_lgss-0.0.4-py3-none-any.whl (90 kB)\n",
      "Collecting smplx (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c9/33/bd37416aec828e7465652d9e2525fe52de0a29a581f1519cc51a74485091/smplx-0.1.28-py3-none-any.whl (29 kB)\n",
      "Collecting tensorflow-estimator>=1.15.1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d1/da/4f264c196325bb6e37a6285caec5b12a03def489b57cc1fdac02bb6272cd/tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tf-slim (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Collecting thop (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bb/0f/72beeab4ff5221dc47127c80f8834b4bcd0cb36f6ba91c0b1d04a1233403/thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Collecting timm>=0.4.9 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7a/bd/2c56be7a3b5bc71cf85a405246b89d5359f942c9f7fb6db6306d9d056092/timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-scatter (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/db/ae/3dee934b7118aec8528a6832dbb3cf079e13dd442c4600cae8d29a4f9fea/torch_scatter-2.1.1.tar.gz (107 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torchmetrics>=0.6.2 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.11.2)\n",
      "Collecting torchsummary>=1.5.1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Requirement already satisfied: torchvision in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.14.1)\n",
      "Requirement already satisfied: transformers>=4.26.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (4.29.2)\n",
      "Collecting trimesh (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c9/10/c5925a556ae5eebca155524443cb94d84ba5715b56085fbbdd8438eb5509/trimesh-3.23.5-py3-none-any.whl (685 kB)\n",
      "Collecting ujson (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e2/a5/3e4a004c2626340b6149d74dd529027d7166cfd86cadd27decf8480ac149/ujson-5.8.0-cp39-cp39-macosx_11_0_arm64.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting utils (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/55/e6/c2d2b2703e7debc8b501caae0e6f7ead148fd0faa3c8131292a599930029/utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting videofeatures-clipit>=1.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/videofeatures_clipit-1.0-py3-none-any.whl (35 kB)\n",
      "Collecting yacs (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting boto3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7f/34/c2bcec634de677a7d05a868e72fd945bd40a2faf2ce249d773bd96c7eec2/boto3-1.28.46-py3-none-any.whl (135 kB)\n",
      "Collecting embeddings (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/bd/da/55d07bcdaac48b293aa88d797be3d89f6b960e2f71565dd64204fa0b6a4f/embeddings-0.0.8-py3-none-any.whl (12 kB)\n",
      "Collecting jieba>=0.42.1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (3.7.1)\n",
      "Collecting megatron-util (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/megatron_util-1.3.2-py3-none-any.whl (182 kB)\n",
      "Collecting nltk (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: protobuf<3.21.0,>=3.19.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (3.20.3)\n",
      "Collecting pythainlp (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1b/27/f447f51e07467641b336496586d0dca93d551e7fbf40eb766b3c2a699fd6/pythainlp-4.0.2-py3-none-any.whl (13.4 MB)\n",
      "Collecting pyvi (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2c/27/27ffee2663f42430cf3434da963f04224fec157b90799fe9e92a3564c1a6/pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
      "Collecting rouge (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/32/7c/650ae86f92460e9e8ef969cc5008b24798dcf56a9a8947d04c78f550b3f5/rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: sacremoses>=0.0.41 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.0.43)\n",
      "Requirement already satisfied: sentencepiece in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.1.99)\n",
      "Collecting seqeval (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting spacy>=2.3.5 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ad/5d/185edd1015e6cd3914060be29a0a1cce9655e9cab48eaddf92ae4aad4656/spacy-3.6.1-cp39-cp39-macosx_11_0_arm64.whl (6.6 MB)\n",
      "Collecting stanza (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3a/71/8ae5ed0834c9f8d70f763c6e2a13e9beb36d464ac8efe0d19ecd767d254c/stanza-1.5.1-py3-none-any.whl (865 kB)\n",
      "Collecting subword-nmt>=0.3.8 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1b/9a/488ecac22d78eb429928b9ee4f6b6c692e116ca4bd43ef42a475698def32/subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
      "Collecting termcolor (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/67/e1/434566ffce04448192369c1a282931cf4ae593e91907558eaecd2e9f2801/termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: tokenizers in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.11.4)\n",
      "Collecting zhconv (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/25/47/c8ae2d5d4025e253211ff3d8c163f457db1da94976cb582337a5ab76cb87/zhconv-1.4.3.tar.gz (211 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/15/80/44286939ca215e88fa827b2aeb6fa3fd2b4a7af322485c7170d6f9fd96e0/cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of modelscope[audio,cv,multi-modal,nlp,science] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2b/17/53845f398e340217ecb2169033f547f640db3663ffb0fb5a6218c5f3bfec/modelscope-1.8.4-py3-none-any.whl (4.9 MB)\n",
      "Collecting diffusers==0.18.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/af/0c/ac0d96b7cdb3168b71758f0a3b600fa3ca725f1d6bf2121acf1b62ec868f/diffusers-0.18.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting en-core-web-sm>=2.3.5 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1f/2c/8e15d72c63b0b5dc726d0607bfcd6528e71d18d67ece7c6b9bb02f1005fe/modelscope-1.8.3-py3-none-any.whl (4.9 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e5/28/64fcd05d1fc1b1f4e64eb530fe8ab3d0d5bc437f456c073173cb8a0d264f/modelscope-1.8.1-py3-none-any.whl (4.8 MB)\n",
      "Collecting numpy<=1.22.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/18/e7/044b6de4dda08312d3a6ad6d60f57043961d872e0e8e3035e3e9df23cad6/numpy-1.22.0-cp39-cp39-macosx_11_0_arm64.whl (12.8 MB)\n",
      "Collecting pandas<1.4.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/99/f0/f99700ef327e51d291efdf4a6de29e685c4d198cbf8531541fc84d169e0e/pandas-1.3.5.tar.gz (4.7 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8a/cf/fd6432cc9b01d4fec8ebb166d3d86845cea4db673d9c832d76695ea98791/modelscope-1.8.0-py3-none-any.whl (4.8 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/27/28/67b27a6d44f05fe3496569c95ff93bed4c6f111847d93db9ac80b33a607b/modelscope-1.7.1-py3-none-any.whl (4.5 MB)\n",
      "Collecting diffusers<=0.15.0,>=0.13.1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/13/43/d4ae69ba5f503d58c7aef13f0f93d9c84694652dc2a16f8ea3d8246ebe95/diffusers-0.15.0-py3-none-any.whl (851 kB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b4/ad/640740fb5f18387476940f5ff9b9f19a5b667c890303699efbe8168cab67/modelscope-1.7.0-py3-none-any.whl (4.5 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c6/b1/729ef4df3aa1804e0786407d2fcdc743383bc3dd475aa4a7da4d66c27c7f/modelscope-1.6.1-py3-none-any.whl (4.4 MB)\n",
      "Collecting datasets<=2.8.0,>=2.7.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/24/57/6b07e4dc51479ae3e9bbc774af348b0307e2b66957ceae94d25e3f9d7dcf/datasets-2.8.0-py3-none-any.whl (452 kB)\n",
      "Collecting diffusers<0.15.0,>=0.13.1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/eb/b4/5f719d41ebd5dc1c75a992e875cf7a8d402fb4acfe373eb04e4b7d805123/diffusers-0.14.0-py3-none-any.whl (737 kB)\n",
      "Collecting scikit-image>=0.19.3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c4/09/0b465a48f9bc7e848538f82e62811978932132b1edd50da758a9243cef5a/scikit_image-0.21.0-cp39-cp39-macosx_12_0_arm64.whl (12.4 MB)\n",
      "Collecting librosa==0.9.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e4/1c/23ef2fd02913d65d43dc7516fc829af709314a66c6f0bdc2e361fdcecc2d/librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "Collecting pycocoevalcap>=1.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/08/f9/466f289f1628296b5e368940f89e3cfcfb066d15ddc02ff536dc532b1c93/pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
      "Collecting pycocotools>=2.0.4 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bb/86/480aff3c16abf2cdc63c708b3e02ca4dee1d47de114996c6c3446c67b808/pycocotools-2.0.7-cp39-cp39-macosx_10_9_universal2.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.8/169.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/00/eb/3b2152f9c3a50d265f3e75529254228ace8a86e9a4397f3004f1e3be7825/pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
      "Collecting rapidfuzz (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e7/c4/c5914e774eea3a277da175b42b8c86b6706110707390a41aafc463fe9ee3/rapidfuzz-3.2.0-cp39-cp39-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rouge-score<=0.0.4 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting sacrebleu (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/30/09/986d4df9ab18e7b12c145851491c89df4ef90f0d380f62bf4490aeb642a4/sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "Requirement already satisfied: safetensors in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.3.3)\n",
      "Collecting soundfile (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/71/87/31d2b9ed58975cec081858c01afaa3c43718eb0f62b5698a876d94739ad0/soundfile-0.12.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "Collecting taming-transformers-rom1504 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c9/dd/be1bec5e221b801fedf7385b6dc7c26cedc435133c4aabfd5f8c16ab5260/taming_transformers_rom1504-0.0.6-py3-none-any.whl (51 kB)\n",
      "Collecting unicodedata2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/00/d7/aaa4d80093893593c19bcae2320f88914f66dcc0cc7fa8f917c62769ff1c/unicodedata2-15.0.0-cp39-cp39-macosx_10_9_universal2.whl (856 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.5/856.5 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting easyasr>=0.0.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/easyasr/linux/easyasr-0.0.7-py3-none-any.whl (3.6 MB)\n",
      "Collecting funasr>=0.5.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9d/f5/e4aa3c17c75a23b09509fa5d7bcfce48b9451dee7a063ba1232a9c2a6f16/funasr-0.7.6-py3-none-any.whl (740 kB)\n",
      "Collecting kaldiio (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6c/32/4fa7c71123f49866b09d462ccdb6bcdfac42e4062a5e83f28fca16593357/kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
      "INFO: pip is looking at multiple versions of modelscope[audio,cv,multi-modal,nlp,science] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/29/cf/ac54b3fcc733c5700eed1780a0363ffd77461e9388456cdbe57f72702fcb/modelscope-1.6.0-py3-none-any.whl (4.4 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2d/cb/506c7e5e45062384e3c54a8edfe82694cea90600b29695fa12b17221def0/modelscope-1.5.2-py3-none-any.whl (4.4 MB)\n",
      "Collecting numpy<1.24.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/9e/9d/ff17c357f7144301da85f8c03d56593cfd2904e9ce89f86c8eefaa96d2d5/numpy-1.23.5-cp39-cp39-macosx_11_0_arm64.whl (13.4 MB)\n",
      "Collecting setuptools==59.8.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8d/25/88b377b99ffb4ad0fc44ff5735fd6be605b2183f743d1ff5c10b7790cea5/setuptools-59.8.0-py3-none-any.whl (952 kB)\n",
      "Collecting pai-easycv<0.10.0,>=0.8 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d7/c4/0f1e96c5ffe7d48bde7b31856b4b871e60e99c91674137e9e544adcded3f/pai_easycv-0.9.0-py3-none-any.whl (6.7 MB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/85/59/cedd029dfde256e34f9d7b256796186ec09bd981695c70ac9a8c2c757719/modelscope-1.5.1-py3-none-any.whl (4.4 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/58/a9/9be740b1c1cb2bc7e50e585b772b1fffb2f745cdbf9c4840f7798e74fe8f/modelscope-1.5.0-py3-none-any.whl (4.4 MB)\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.4/modelscope-1.4.3-py3-none-any.whl (4.2 MB)\n",
      "Collecting jsonplus (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d6/0a/0438f4131477fa827431137eec9c4bd11e7884065e5812dc989c80d91e82/jsonplus-0.8.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting mmdet>=2.25.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c5/ba/5e9726a4a1c5dd4df1ee8cbdabc9b255215cf94581cd1b5670c8d6c42af5/mmdet-3.1.0-py3-none-any.whl (2.0 MB)\n",
      "Collecting mmsegmentation (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/35/69/7eafb0a939a22829105579521f381ebbf58ff18afd5e2f6f7ec7b8156016/mmsegmentation-1.1.1-py3-none-any.whl (926 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3c/33/553d775dd38932af489f6b9a2a192c60a099632494f9e9cc7e2e86ac8980/modelscope-1.4.2-py3-none-any.whl (4.2 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f2/2b/d729264e2c7c12a0f5fddbd8843d039b994b6fcfb5c2a4557496a4e9df2c/modelscope-1.4.1-py3-none-any.whl (4.2 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6f/11/dc31bcd00f36e609d6017321ba85a7bd9335ddd5ac89efcb4a2d6eae9c41/modelscope-1.4.0-py3-none-any.whl (4.2 MB)\n",
      "Collecting librosa (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e2/a2/4f639c1168d7aada749a896afb4892a831e2041bebdcf636aebfe9e86556/librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/52/3c/b8da78fb0ef5cd7751c11f3c76f55f0db2be9cf8e0eddf03bb7cb2330d6c/modelscope-1.3.2-py3-none-any.whl (3.9 MB)\n",
      "Collecting pai-easycv>=0.8 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ed/2d/284dd3483050d943ac86074e1c0acbe7df5e63abcaf7f5ae664b5b72c7e6/pai_easycv-0.11.4-py3-none-any.whl (6.8 MB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b1/c8/88828d93eb2394a202f237fd63ee74155b08dec2cae8ef6d2aee447299ef/modelscope-1.3.1-py3-none-any.whl (3.9 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/63/d2/42e92095141bc598a2e518a1ec214fbe04d1bb8701aead09b2473cdf194d/modelscope-1.3.0-py3-none-any.whl (3.9 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b4/f4/1bc67ee6e13d8803adc56e612cae6cb00c3ae0e71091f67de836dfb24304/modelscope-1.2.1-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: tensorboard in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (2.14.0)\n",
      "Collecting text2sql-lgesql (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/text2sql_lgesql-1.3.0-py3-none-any.whl (102 kB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/87/e3/e202aa4f4bcfc7a3493071f5635db4629e267d699703e0c4995f6623906f/modelscope-1.2.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting bitstring (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/59/bc/bbc41ad3546f23855a2c21dc6afcd8b148ccec2e51a5af145199abfa4b9e/bitstring-4.1.2-py3-none-any.whl (59 kB)\n",
      "Collecting espnet==202204 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2d/67/00dad105a51416286bd4a34eecc655ca3d47137ef75d6aa6c08807e710ac/espnet-202204-py3-none-any.whl (1.0 MB)\n",
      "Collecting funtextprocessing>=0.1.1 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/funtextprocessing-0.1.1-py3-none-any.whl (3.0 MB)\n",
      "Collecting greenlet>=1.1.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3f/1a/1a48b85490d93af5c577e6ab4d032ee3fe85c4c6d8656376f28d6d403fb1/greenlet-2.0.2-cp39-cp39-macosx_11_0_arm64.whl (196 kB)\n",
      "Collecting h5py (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e4/78/0a42a0c518b7a2cee32f9645ebf343b78390428c6889e4ef60af51fbbd3c/h5py-3.9.0-cp39-cp39-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Collecting inflect (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fb/c6/d9feb758be584f729424390af24687d3a4363d968164f94079f83cd536b4/inflect-7.0.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (0.18.1)\n",
      "Collecting keras (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/fe/58/34d4d8f1aa11120c2d36d7ad27d0526164b1a8ae45990a2fede31d0e59bf/keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.1/modelscope-1.1.4-py3-none-any.whl (2.5 MB)\n",
      "Collecting datasets<=2.5.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/39/f5/0f485f7cd79699fdc665f5215b00df20b98298e204d241cbad21b6b8fd14/datasets-2.5.2-py3-none-any.whl (432 kB)\n",
      "Collecting pai-easynlp (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/dependencies/pai_easynlp-0.0.7-py2.py3-none-any.whl (698 kB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f2/43/974e13bc086007572d0dd8e88b2fe3f1b1771fe49f9218288e18fdc23c72/modelscope-1.1.3-py3-none-any.whl (2.4 MB)\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.1/modelscope-1.1.2-py3-none-any.whl (2.4 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/8b/98/827342b578e91c66889da523b76000f179e15122312e5b3acf01aca263e5/modelscope-1.1.1-py3-none-any.whl (2.4 MB)\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.1/modelscope-1.1.0-py3-none-any.whl (2.4 MB)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/71/44/23c5de7904784bc628a3dfc2b622877c5ba20e04f1068a7b083dda528613/modelscope-1.0.4-py3-none-any.whl (2.3 MB)\n",
      "Collecting ofa>=0.0.2 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d7/72/9ce788c3b80266e0a62ef0049d62ad7658482f2661c2d682661b6bfea9e4/ofa-0.1.0.post202307202001-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.0/modelscope-1.0.3-py3-none-any.whl (2.3 MB)\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.0/modelscope-1.0.2-py3-none-any.whl (2.2 MB)\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.0/modelscope-1.0.1-py3-none-any.whl (2.2 MB)\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v1.0/modelscope-1.0.0-py3-none-any.whl (2.2 MB)\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.5/modelscope-0.5.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[33mWARNING: modelscope 0.5.1 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.5/modelscope-0.5.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[33mWARNING: modelscope 0.5.0 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.7-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.7 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting espnet>=202204 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/d2/73/1a9bb43b40eacf228e0255fcfa83ea50e03dd90ba33895caedb31b5f0646/espnet-202308-py3-none-any.whl (1.6 MB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.6-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.6 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.5-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.5 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.4-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.4 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.3-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.3 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.2 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.1 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.4/modelscope-0.4.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[33mWARNING: modelscope 0.4.0 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[33mWARNING: modelscope 0.3.7 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets==2.1.0 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3e/cf/19ab60e71740d369d5804d352f6c8a3d8f107a2d1664bd538cb3c475c2ce/datasets-2.1.0-py3-none-any.whl (325 kB)\n",
      "Collecting modelscope[audio,cv,multi-modal,nlp,science]\n",
      "  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.6-py3-none-any.whl (1.0 MB)\n",
      "\u001b[33mWARNING: modelscope 0.3.6 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.5-py3-none-any.whl (1.0 MB)\n",
      "\u001b[33mWARNING: modelscope 0.3.5 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "\u001b[33mWARNING: modelscope 0.3.4 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.3-py3-none-any.whl (1.0 MB)\n",
      "\u001b[33mWARNING: modelscope 0.3.3 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.2-py3-none-any.whl (986 kB)\n",
      "\u001b[33mWARNING: modelscope 0.3.2 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.3/modelscope-0.3.1-py3-none-any.whl (978 kB)\n",
      "\u001b[33mWARNING: modelscope 0.3.1 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Using cached https://modelscope.oss-cn-beijing.aliyuncs.com/releases/v0.2/modelscope-0.2.5-py3-none-any.whl (380 kB)\n",
      "\u001b[33mWARNING: modelscope 0.2.5 does not provide the extra 'multi-modal'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: modelscope 0.2.5 does not provide the extra 'science'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting protobuf<=3.20,>3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ae/80/9eaa62a2afcc5407a6b7d2652c208f073df3a5c83b5bff90bf99553fbcf2/protobuf-3.20.0-py2.py3-none-any.whl (162 kB)\n",
      "Collecting tokenizers<=0.10.3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/48/2b/b99184cacb1a743edc18290e9127d1b0e658c0c46f2ab5290b27fe865ff4/tokenizers-0.10.3.tar.gz (212 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (1.11.0)\n",
      "Collecting transformers<=4.16.2,>=4.10.3 (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/66/43/e657fd438b2e93221ce06ab0db0dcdf61eb33c79a0d3307940b82d554c4e/transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "Requirement already satisfied: lxml in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from modelscope[audio,cv,multi-modal,nlp,science]) (4.9.2)\n",
      "Collecting nara-wpe (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e0/11/195e4ad1a878560729adbf6da914e1721aa22d0b8b5245499f75967b3e2a/nara_wpe-0.0.9-py3-none-any.whl (33 kB)\n",
      "Collecting numpy (from modelscope[audio,cv,multi-modal,nlp,science])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/31/0a/5df350c29a06835d534a6c4f5681075304da38d85f1c69e5226a635a67ce/numpy-1.18.0.zip (5.4 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[56 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Running from numpy source directory.\n",
      "  \u001b[31m   \u001b[0m <string>:425: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/tools/cythonize.py:75: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  \u001b[31m   \u001b[0m   required_version = LooseVersion('0.29.13')\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/tools/cythonize.py:77: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  \u001b[31m   \u001b[0m   if LooseVersion(cython_version) < required_version:\n",
      "  \u001b[31m   \u001b[0m warning: _philox.pyx:19:0: The 'DEF' statement is deprecated and will be removed in a future Cython version. Consider using global variables, constants, and in-place literals instead. See https://github.com/cython/cython/issues/4310\n",
      "  \u001b[31m   \u001b[0m warning: /private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/numpy/__init__.pxd:17:0: The 'DEF' statement is deprecated and will be removed in a future Cython version. Consider using global variables, constants, and in-place literals instead. See https://github.com/cython/cython/issues/4310\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error compiling Cython file:\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m ...\n",
      "  \u001b[31m   \u001b[0m             self.rng_state.ctr.v[i] = counter[i]\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         self._reset_state_variables()\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         self._bitgen.state = <void *>&self.rng_state\n",
      "  \u001b[31m   \u001b[0m         self._bitgen.next_uint64 = &philox_uint64\n",
      "  \u001b[31m   \u001b[0m                                    ^\n",
      "  \u001b[31m   \u001b[0m ------------------------------------------------------------\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.\n",
      "  \u001b[31m   \u001b[0m Processing numpy/random/_bounded_integers.pxd.in\n",
      "  \u001b[31m   \u001b[0m Processing numpy/random/_philox.pyx\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/tools/cythonize.py\", line 238, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/tools/cythonize.py\", line 234, in main\n",
      "  \u001b[31m   \u001b[0m     find_process_files(root_dir)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/tools/cythonize.py\", line 225, in find_process_files\n",
      "  \u001b[31m   \u001b[0m     process(root_dir, fromfile, tofile, function, hash_db)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/tools/cythonize.py\", line 191, in process\n",
      "  \u001b[31m   \u001b[0m     processor_function(fromfile, tofile)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-install-23csj783/numpy_6dd475b3980847f487e88181cb52a4f0/tools/cythonize.py\", line 80, in process_pyx\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/subprocess.py\", line 373, in check_call\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, cmd)\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['/Users/beyond/anaconda3/envs/visgpt3_9/bin/python', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m Cythonizing sources\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(metadata_directory, config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-build-env-8w5bcgra/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 396, in prepare_metadata_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-build-env-8w5bcgra/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 507, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/ls/7g9ww_m960s2t279njn8xtlw0000gn/T/pip-build-env-8w5bcgra/overlay/lib/python3.9/site-packages/setuptools/build_meta.py\", line 341, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 450, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 433, in setup_package\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 240, in generate_cython\n",
      "  \u001b[31m   \u001b[0m RuntimeError: Running cythonize failed!\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: xformers in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (0.0.21)\n",
      "Collecting torch>=1.12 (from xformers)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3c/67/7e19ebc15430f7385baee359383744c03d3600b51def9b399d0b8686e892/torch-2.0.1-cp39-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "Requirement already satisfied: numpy in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from xformers) (1.24.3)\n",
      "Requirement already satisfied: filelock in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torch>=1.12->xformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torch>=1.12->xformers) (4.6.3)\n",
      "Requirement already satisfied: sympy in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torch>=1.12->xformers) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torch>=1.12->xformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torch>=1.12->xformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from jinja2->torch>=1.12->xformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from sympy->torch>=1.12->xformers) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "Successfully installed torch-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install \"modelscope[audio,cv,nlp,multi-modal,science]\" -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html\n",
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842872e1-ed10-4c7f-829c-24bf07098e86",
   "metadata": {},
   "source": [
    "### 执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9ee7f2d-6a6e-4219-8a2d-09ea1d2ad0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 08:48:12,310 - modelscope - INFO - Use user-specified model revision: v1.0.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'init_empty_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m snapshot_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaichuan-inc/Baichuan2-13B-Chat\u001b[39m\u001b[38;5;124m\"\u001b[39m, revision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1.0.1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_dir, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m                               trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m GenerationConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_dir)\n\u001b[1;32m      9\u001b[0m messages \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/modelscope/utils/hf_util.py:164\u001b[0m, in \u001b[0;36mget_wrapped_class.<locals>.ClassWrapper.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m     check_hf_code(model_dir, module_class, trust_remote_code)\n\u001b[0;32m--> 164\u001b[0m module_obj \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                                          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoModel\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    168\u001b[0m     module_obj\u001b[38;5;241m.\u001b[39mmodel_dir \u001b[38;5;241m=\u001b[39m model_dir\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:462\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m     class_ref \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mauto_map[\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n\u001b[1;32m    459\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m get_class_from_dynamic_module(\n\u001b[1;32m    460\u001b[0m         class_ref, pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    461\u001b[0m     )\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    466\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Baichuan2-13B-Chat/modeling_baichuan.py:665\u001b[0m, in \u001b[0;36mBaichuanForCausalLM.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m         dispatch_model(model, device_map\u001b[38;5;241m=\u001b[39mdevice_map)\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m--> 665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBaichuanForCausalLM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/modelscope/utils/hf_util.py:72\u001b[0m, in \u001b[0;36mpatch_model_base.<locals>.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     model_dir \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mori_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages/transformers/modeling_utils.py:2608\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2606\u001b[0m     init_contexts \u001b[38;5;241m=\u001b[39m [deepspeed\u001b[38;5;241m.\u001b[39mzero\u001b[38;5;241m.\u001b[39mInit(config_dict_or_path\u001b[38;5;241m=\u001b[39mdeepspeed_config())] \u001b[38;5;241m+\u001b[39m init_contexts\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m load_in_8bit \u001b[38;5;129;01mor\u001b[39;00m low_cpu_mem_usage:\n\u001b[0;32m-> 2608\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(\u001b[43minit_empty_weights\u001b[49m())\n\u001b[1;32m   2610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   2611\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_empty_weights' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modelscope import snapshot_download, AutoModelForCausalLM, AutoTokenizer,GenerationConfig\n",
    "model_dir = snapshot_download(\"baichuan-inc/Baichuan2-13B-Chat\", revision='v1.0.1')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, device_map=\"auto\", \n",
    "                              trust_remote_code=True, torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map=\"auto\", \n",
    "                              trust_remote_code=True, torch_dtype=torch.float16)\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_dir)\n",
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"讲解一下“温故而知新”\"})\n",
    "response = model.chat(tokenizer, messages)\n",
    "print(response)\n",
    "messages.append({'role': 'assistant', 'content': response})\n",
    "messages.append({\"role\": \"user\", \"content\": \"背诵一下将进酒\"})\n",
    "response = model.chat(tokenizer, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec71517-c83d-4d3e-8d60-431905eeec47",
   "metadata": {},
   "source": [
    "### 安装sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce1c0264-4046-4926-be4e-22a1782a571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torch==1.11.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ec/bc/5e2b92f471496da1629e156553c8d92e0df667743f3128dd5e4db287ddb9/torch-1.11.0-cp39-none-macosx_11_0_arm64.whl (43.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (0.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torch==1.11.0) (4.6.3)\n",
      "Requirement already satisfied: numpy in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/beyond/anaconda3/envs/visgpt3_9/lib/python3.9/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.5.0 requires torch>=1.13.0, but you have torch 1.11.0 which is incompatible.\n",
      "xformers 0.0.21 requires torch>=1.12, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.11.0 torchvision torchaudio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
